{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cuttings import *\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tf\n",
    "from torch.utils import data \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision for pre-trained models\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxNormalization(object):\n",
    "    \"\"\"\n",
    "    Normalized (Min-Max) the image.\n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=0, vmax=1):\n",
    "        \"\"\"\n",
    "        Constructor of the grayscale transform.\n",
    "        ----------\n",
    "        INPUT\n",
    "            |---- vmin (float / int) the desired minimum value.\n",
    "            |---- vmax (float / int) the desired maximum value.\n",
    "        OUTPUT\n",
    "            |---- None\n",
    "        \"\"\"\n",
    "        self.vmin = vmin\n",
    "        self.vmax = vmax\n",
    "\n",
    "    def __call__(self, image, mask=None):\n",
    "        \"\"\"\n",
    "        Apply a Min-Max Normalization to the image.\n",
    "        ----------\n",
    "        INPUT\n",
    "            |---- image (PIL.Image) the image to normalize.\n",
    "        OUTPUT\n",
    "            |---- image (np.array) the normalized image.\n",
    "        \"\"\"\n",
    "        arr = np.array(image).astype('float32')\n",
    "        arr = (arr - arr.min()) / (arr.max() - arr.min())\n",
    "        arr = (self.vmax - self.vmin) * arr + self.vmin\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cuttings_Dataset(data.Dataset):\n",
    "    def __init__(self, sample_df, data_path, data_augmentation=True):\n",
    "        \"\"\"\n",
    "        Constructor of the dataset.\n",
    "        \"\"\"\n",
    "        data.Dataset.__init__(self)\n",
    "        self.sample_df = sample_df\n",
    "        self.data_path = data_path\n",
    "        self.data_augmentation = data_augmentation\n",
    "        \n",
    "        self.transform =  tf.Compose([tf.Grayscale(num_output_channels=3),\n",
    "                                        tf.Resize(224),\n",
    "                                        MinMaxNormalization(),\n",
    "                                        tf.ToTensor(),\n",
    "                                        tf.Normalize((0.5205568,0.5205568,0.5205568),(0.33119723,0.33119723,0.33119723))])\n",
    "        \n",
    "        if data_augmentation:\n",
    "            self.transform = tf.Compose([tf.Grayscale(num_output_channels=3),\n",
    "                                            tf.Resize(224),\n",
    "                                            tf.RandomVerticalFlip(p=0.5),\n",
    "                                            tf.RandomHorizontalFlip(p=0.5),\n",
    "                                            tf.RandomRotation([-90,90],resample=False, expand=False, center=None, fill=None),\n",
    "                                            MinMaxNormalization(),\n",
    "                                            tf.ToTensor(),\n",
    "                                            tf.Normalize((0.5205568,0.5205568,0.5205568),(0.33119723,0.33119723,0.33119723))])\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return self.sample_df.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get an item from the dataset.\n",
    "        \"\"\"\n",
    "        # load image\n",
    "        im = Image.open(self.data_path + self.sample_df.loc[idx,'path'])\n",
    "        # load label\n",
    "        label = torch.tensor(self.sample_df.loc[idx,'rock_type'])\n",
    "        \n",
    "        im = self.transform(im)\n",
    "        return im,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['ML', 'MS','BL','GN','OL'])\n",
    "\n",
    "date = '05_05_20'\n",
    "\n",
    "df = pd.read_csv('train/csv_'+date+'/train'+date+'_final.csv',index_col=0)\n",
    "\n",
    "train,val = train_test_split(df,test_size=0.2,random_state=0,stratify=df['rock_type'])\n",
    "cuttings_datasets = {}\n",
    "\n",
    "cuttings_datasets['train'] = Cuttings_Dataset(train.reset_index(drop=True),'',data_augmentation=True)\n",
    "cuttings_datasets['val'] = Cuttings_Dataset(val.reset_index(drop=True),'',data_augmentation=False)\n",
    "cuttings_datasets['test'] = Cuttings_Dataset(pd.read_csv('test'+'/csv_'+date+'/'+'test'+date+'_final.csv',index_col=0),'',data_augmentation=False)\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(cuttings_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(cuttings_datasets[x]) for x in ['train','val','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "# when True we only update the reshaped layer params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, feature_extract=True, use_pretrained=True):\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = initialize_model(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss_train = 0.0\n",
    "        running_corrects_train = 0\n",
    "            \n",
    "        model.train()# Set model to training mode\n",
    "        \n",
    "        # Iterate over data Training\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            inputs.require_grad = True\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward + optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss_train += loss.item() * inputs.size(0)\n",
    "            running_corrects_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "        epoch_loss_train = running_loss_train / dataset_sizes[\"train\"]\n",
    "        epoch_acc_train = running_corrects_train.double() / dataset_sizes[\"train\"]\n",
    "        loss_train.append(epoch_loss_train)\n",
    "        acc_train.append(epoch_acc_train)\n",
    "        \n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                \"Train\", epoch_loss_train, epoch_acc_train))\n",
    "        \n",
    "        running_loss_val = 0.0\n",
    "        running_corrects_val = 0\n",
    "            \n",
    "        model.eval() # Set model to evaluate mode\n",
    "        \n",
    "        # Iterate over data Evaluation\n",
    "        for inputs, labels in dataloaders[\"val\"]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                loss = criterion(outputs, labels)   \n",
    "\n",
    "            # statistics\n",
    "            running_loss_val += loss.item() * inputs.size(0)\n",
    "            running_corrects_val += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss_val = running_loss_val / dataset_sizes[\"val\"]\n",
    "        epoch_acc_val = running_corrects_val.double() / dataset_sizes[\"val\"]\n",
    "        loss_val.append(epoch_loss_val)\n",
    "        acc_val.append(epoch_acc_val)\n",
    "        \n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                \"Val\", epoch_loss_val, epoch_acc_val))\n",
    "            \n",
    "        # deep copy the model\n",
    "        if epoch_acc_val > best_acc:\n",
    "            best_acc = epoch_acc_val\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_train, acc_train, loss_val, acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediciton\n",
    "def prediciton(model):\n",
    "    preds_vec = []\n",
    "    true_vec = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            preds_vec+=preds.tolist()\n",
    "            true_vec+=labels.tolist()\n",
    "    return preds_vec, true_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '30_06_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "Train Loss: 0.9797 Acc: 0.6432\n",
      "Val Loss: 0.8455 Acc: 0.7390\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "Train Loss: 0.6748 Acc: 0.7598\n",
      "Val Loss: 0.7168 Acc: 0.7530\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "Train Loss: 0.6299 Acc: 0.7705\n",
      "Val Loss: 0.6311 Acc: 0.7950\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "Train Loss: 0.5611 Acc: 0.7903\n",
      "Val Loss: 0.6389 Acc: 0.7750\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "Train Loss: 0.5692 Acc: 0.7920\n",
      "Val Loss: 0.6509 Acc: 0.7650\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "Train Loss: 0.5356 Acc: 0.8023\n",
      "Val Loss: 0.5998 Acc: 0.7940\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "Train Loss: 0.5070 Acc: 0.8140\n",
      "Val Loss: 0.6153 Acc: 0.7880\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "Train Loss: 0.5180 Acc: 0.8133\n",
      "Val Loss: 0.5972 Acc: 0.8050\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "Train Loss: 0.5022 Acc: 0.8130\n",
      "Val Loss: 0.5971 Acc: 0.7920\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "Train Loss: 0.4813 Acc: 0.8173\n",
      "Val Loss: 0.6422 Acc: 0.7580\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "Train Loss: 0.4872 Acc: 0.8175\n",
      "Val Loss: 0.6718 Acc: 0.7360\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "Train Loss: 0.4877 Acc: 0.8200\n",
      "Val Loss: 0.5693 Acc: 0.8140\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "Train Loss: 0.4813 Acc: 0.8195\n",
      "Val Loss: 0.5432 Acc: 0.8190\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "Train Loss: 0.4624 Acc: 0.8325\n",
      "Val Loss: 0.5720 Acc: 0.7950\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "Train Loss: 0.4953 Acc: 0.8145\n",
      "Val Loss: 0.5530 Acc: 0.8000\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "Train Loss: 0.4720 Acc: 0.8275\n",
      "Val Loss: 0.6132 Acc: 0.7780\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "Train Loss: 0.4795 Acc: 0.8257\n",
      "Val Loss: 0.5458 Acc: 0.8150\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "Train Loss: 0.4668 Acc: 0.8227\n",
      "Val Loss: 0.5833 Acc: 0.7950\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "Train Loss: 0.4547 Acc: 0.8233\n",
      "Val Loss: 0.5299 Acc: 0.8110\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "Train Loss: 0.4794 Acc: 0.8173\n",
      "Val Loss: 0.5509 Acc: 0.8040\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "Train Loss: 0.4581 Acc: 0.8307\n",
      "Val Loss: 0.5416 Acc: 0.8090\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "Train Loss: 0.4621 Acc: 0.8355\n",
      "Val Loss: 0.5871 Acc: 0.7910\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "Train Loss: 0.4764 Acc: 0.8257\n",
      "Val Loss: 0.5900 Acc: 0.7900\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "Train Loss: 0.4562 Acc: 0.8323\n",
      "Val Loss: 0.5484 Acc: 0.8110\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "Train Loss: 0.4435 Acc: 0.8335\n",
      "Val Loss: 0.5328 Acc: 0.8140\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "Train Loss: 0.4693 Acc: 0.8233\n",
      "Val Loss: 0.5325 Acc: 0.8230\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "Train Loss: 0.4693 Acc: 0.8235\n",
      "Val Loss: 0.5323 Acc: 0.8110\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "Train Loss: 0.4701 Acc: 0.8290\n",
      "Val Loss: 0.5509 Acc: 0.8030\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "Train Loss: 0.4626 Acc: 0.8310\n",
      "Val Loss: 0.5279 Acc: 0.8230\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "Train Loss: 0.4350 Acc: 0.8448\n",
      "Val Loss: 0.5776 Acc: 0.7900\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "Train Loss: 0.4607 Acc: 0.8263\n",
      "Val Loss: 0.5428 Acc: 0.8120\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "Train Loss: 0.4601 Acc: 0.8310\n",
      "Val Loss: 0.5600 Acc: 0.8000\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "Train Loss: 0.4655 Acc: 0.8277\n",
      "Val Loss: 0.5345 Acc: 0.8210\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "Train Loss: 0.4526 Acc: 0.8340\n",
      "Val Loss: 0.5326 Acc: 0.8170\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "Train Loss: 0.4605 Acc: 0.8275\n",
      "Val Loss: 0.5668 Acc: 0.8060\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "Train Loss: 0.4416 Acc: 0.8400\n",
      "Val Loss: 0.5307 Acc: 0.8280\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "Train Loss: 0.4626 Acc: 0.8263\n",
      "Val Loss: 0.5404 Acc: 0.8090\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "Train Loss: 0.4369 Acc: 0.8343\n",
      "Val Loss: 0.5431 Acc: 0.8060\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "Train Loss: 0.4421 Acc: 0.8400\n",
      "Val Loss: 0.5554 Acc: 0.7980\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "Train Loss: 0.4609 Acc: 0.8270\n",
      "Val Loss: 0.5512 Acc: 0.8100\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "Train Loss: 0.4541 Acc: 0.8307\n",
      "Val Loss: 0.5613 Acc: 0.8020\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "Train Loss: 0.4735 Acc: 0.8230\n",
      "Val Loss: 0.6286 Acc: 0.7710\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "Train Loss: 0.4594 Acc: 0.8320\n",
      "Val Loss: 0.5354 Acc: 0.8080\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "Train Loss: 0.4525 Acc: 0.8345\n",
      "Val Loss: 0.5604 Acc: 0.8020\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "Train Loss: 0.4335 Acc: 0.8450\n",
      "Val Loss: 0.5512 Acc: 0.8100\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "Train Loss: 0.4466 Acc: 0.8363\n",
      "Val Loss: 0.5472 Acc: 0.8000\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "Train Loss: 0.4672 Acc: 0.8277\n",
      "Val Loss: 0.5578 Acc: 0.8050\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "Train Loss: 0.4653 Acc: 0.8237\n",
      "Val Loss: 0.5328 Acc: 0.8140\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "Train Loss: 0.4570 Acc: 0.8365\n",
      "Val Loss: 0.5344 Acc: 0.8140\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "Train Loss: 0.4627 Acc: 0.8310\n",
      "Val Loss: 0.5073 Acc: 0.8230\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "Train Loss: 0.4585 Acc: 0.8370\n",
      "Val Loss: 0.5092 Acc: 0.8340\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "Train Loss: 0.4175 Acc: 0.8423\n",
      "Val Loss: 0.5234 Acc: 0.8160\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "Train Loss: 0.4281 Acc: 0.8453\n",
      "Val Loss: 0.5208 Acc: 0.8090\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "Train Loss: 0.4895 Acc: 0.8230\n",
      "Val Loss: 0.5302 Acc: 0.8170\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "Train Loss: 0.4722 Acc: 0.8243\n",
      "Val Loss: 0.5198 Acc: 0.8150\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "Train Loss: 0.4451 Acc: 0.8353\n",
      "Val Loss: 0.5049 Acc: 0.8260\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "Train Loss: 0.4591 Acc: 0.8250\n",
      "Val Loss: 0.5199 Acc: 0.8250\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "Train Loss: 0.4455 Acc: 0.8343\n",
      "Val Loss: 0.5499 Acc: 0.8020\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "Train Loss: 0.4118 Acc: 0.8500\n",
      "Val Loss: 0.5406 Acc: 0.8140\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "Train Loss: 0.4509 Acc: 0.8330\n",
      "Val Loss: 0.5674 Acc: 0.7980\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "Train Loss: 0.4499 Acc: 0.8343\n",
      "Val Loss: 0.5155 Acc: 0.8230\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "Train Loss: 0.4481 Acc: 0.8415\n",
      "Val Loss: 0.5359 Acc: 0.8080\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "Train Loss: 0.4090 Acc: 0.8485\n",
      "Val Loss: 0.5252 Acc: 0.8170\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "Train Loss: 0.4477 Acc: 0.8410\n",
      "Val Loss: 0.5335 Acc: 0.8190\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "Train Loss: 0.4478 Acc: 0.8345\n",
      "Val Loss: 0.5257 Acc: 0.8160\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "Train Loss: 0.4601 Acc: 0.8340\n",
      "Val Loss: 0.5706 Acc: 0.7840\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "Train Loss: 0.4186 Acc: 0.8440\n",
      "Val Loss: 0.5439 Acc: 0.7980\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "Train Loss: 0.4490 Acc: 0.8347\n",
      "Val Loss: 0.5708 Acc: 0.7980\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "Train Loss: 0.4276 Acc: 0.8415\n",
      "Val Loss: 0.5907 Acc: 0.7800\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "Train Loss: 0.4363 Acc: 0.8370\n",
      "Val Loss: 0.5668 Acc: 0.8090\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "Train Loss: 0.4470 Acc: 0.8370\n",
      "Val Loss: 0.5206 Acc: 0.8210\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "Train Loss: 0.4566 Acc: 0.8380\n",
      "Val Loss: 0.5918 Acc: 0.7910\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "Train Loss: 0.4402 Acc: 0.8397\n",
      "Val Loss: 0.5207 Acc: 0.8280\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "Train Loss: 0.4527 Acc: 0.8305\n",
      "Val Loss: 0.5737 Acc: 0.7990\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "Train Loss: 0.4394 Acc: 0.8340\n",
      "Val Loss: 0.5193 Acc: 0.8220\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "Train Loss: 0.4428 Acc: 0.8375\n",
      "Val Loss: 0.5124 Acc: 0.8270\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "Train Loss: 0.4385 Acc: 0.8377\n",
      "Val Loss: 0.5214 Acc: 0.8130\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "Train Loss: 0.4379 Acc: 0.8335\n",
      "Val Loss: 0.5144 Acc: 0.8180\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "Train Loss: 0.4489 Acc: 0.8375\n",
      "Val Loss: 0.5035 Acc: 0.8380\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "Train Loss: 0.4262 Acc: 0.8425\n",
      "Val Loss: 0.5294 Acc: 0.8130\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "Train Loss: 0.4559 Acc: 0.8305\n",
      "Val Loss: 0.5446 Acc: 0.8090\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "Train Loss: 0.4454 Acc: 0.8353\n",
      "Val Loss: 0.5658 Acc: 0.8040\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "Train Loss: 0.4492 Acc: 0.8315\n",
      "Val Loss: 0.5237 Acc: 0.8190\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "Train Loss: 0.4276 Acc: 0.8430\n",
      "Val Loss: 0.5029 Acc: 0.8250\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "Train Loss: 0.4184 Acc: 0.8478\n",
      "Val Loss: 0.5356 Acc: 0.8110\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "Train Loss: 0.4350 Acc: 0.8365\n",
      "Val Loss: 0.5059 Acc: 0.8300\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "Train Loss: 0.4331 Acc: 0.8427\n",
      "Val Loss: 0.5573 Acc: 0.7980\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "Train Loss: 0.4310 Acc: 0.8475\n",
      "Val Loss: 0.4926 Acc: 0.8390\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "Train Loss: 0.4333 Acc: 0.8413\n",
      "Val Loss: 0.5461 Acc: 0.8050\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "Train Loss: 0.4578 Acc: 0.8345\n",
      "Val Loss: 0.5520 Acc: 0.7960\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "Train Loss: 0.4434 Acc: 0.8417\n",
      "Val Loss: 0.5342 Acc: 0.8180\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "Train Loss: 0.4090 Acc: 0.8488\n",
      "Val Loss: 0.5784 Acc: 0.8070\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "Train Loss: 0.4317 Acc: 0.8383\n",
      "Val Loss: 0.5145 Acc: 0.8250\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "Train Loss: 0.4416 Acc: 0.8423\n",
      "Val Loss: 0.4938 Acc: 0.8350\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "Train Loss: 0.4432 Acc: 0.8390\n",
      "Val Loss: 0.5502 Acc: 0.7950\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "Train Loss: 0.4516 Acc: 0.8295\n",
      "Val Loss: 0.5597 Acc: 0.8000\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "Train Loss: 0.4293 Acc: 0.8397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5262 Acc: 0.8110\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "Train Loss: 0.4292 Acc: 0.8433\n",
      "Val Loss: 0.5177 Acc: 0.8260\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "Train Loss: 0.4235 Acc: 0.8468\n",
      "Val Loss: 0.5436 Acc: 0.8170\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "Train Loss: 0.4169 Acc: 0.8463\n",
      "Val Loss: 0.5179 Acc: 0.8150\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "Train Loss: 0.4540 Acc: 0.8340\n",
      "Val Loss: 0.5105 Acc: 0.8190\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "Train Loss: 0.4330 Acc: 0.8410\n",
      "Val Loss: 0.5630 Acc: 0.8060\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "Train Loss: 0.4387 Acc: 0.8350\n",
      "Val Loss: 0.5264 Acc: 0.8320\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "Train Loss: 0.4157 Acc: 0.8430\n",
      "Val Loss: 0.5119 Acc: 0.8180\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "Train Loss: 0.4337 Acc: 0.8347\n",
      "Val Loss: 0.4973 Acc: 0.8260\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "Train Loss: 0.4571 Acc: 0.8413\n",
      "Val Loss: 0.5294 Acc: 0.8300\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "Train Loss: 0.4456 Acc: 0.8333\n",
      "Val Loss: 0.5645 Acc: 0.8070\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "Train Loss: 0.4404 Acc: 0.8390\n",
      "Val Loss: 0.5039 Acc: 0.8300\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "Train Loss: 0.4246 Acc: 0.8435\n",
      "Val Loss: 0.5341 Acc: 0.8140\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "Train Loss: 0.3993 Acc: 0.8528\n",
      "Val Loss: 0.5379 Acc: 0.8220\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "Train Loss: 0.4191 Acc: 0.8463\n",
      "Val Loss: 0.5204 Acc: 0.8240\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "Train Loss: 0.4392 Acc: 0.8400\n",
      "Val Loss: 0.5366 Acc: 0.7950\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "Train Loss: 0.4392 Acc: 0.8440\n",
      "Val Loss: 0.5089 Acc: 0.8210\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "Train Loss: 0.4326 Acc: 0.8433\n",
      "Val Loss: 0.5077 Acc: 0.8260\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "Train Loss: 0.4473 Acc: 0.8337\n",
      "Val Loss: 0.5289 Acc: 0.8150\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "Train Loss: 0.4392 Acc: 0.8425\n",
      "Val Loss: 0.5209 Acc: 0.8160\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "Train Loss: 0.4342 Acc: 0.8427\n",
      "Val Loss: 0.5446 Acc: 0.8130\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "Train Loss: 0.4217 Acc: 0.8417\n",
      "Val Loss: 0.5346 Acc: 0.8240\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "Train Loss: 0.4250 Acc: 0.8483\n",
      "Val Loss: 0.5181 Acc: 0.8330\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "Train Loss: 0.4198 Acc: 0.8483\n",
      "Val Loss: 0.5103 Acc: 0.8190\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "Train Loss: 0.4216 Acc: 0.8387\n",
      "Val Loss: 0.5274 Acc: 0.8160\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "Train Loss: 0.4221 Acc: 0.8435\n",
      "Val Loss: 0.5371 Acc: 0.8160\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "Train Loss: 0.4291 Acc: 0.8367\n",
      "Val Loss: 0.4896 Acc: 0.8410\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "Train Loss: 0.4339 Acc: 0.8420\n",
      "Val Loss: 0.5339 Acc: 0.8190\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "Train Loss: 0.4272 Acc: 0.8445\n",
      "Val Loss: 0.5229 Acc: 0.8240\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "Train Loss: 0.4241 Acc: 0.8423\n",
      "Val Loss: 0.5569 Acc: 0.8060\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "Train Loss: 0.4408 Acc: 0.8365\n",
      "Val Loss: 0.5232 Acc: 0.8250\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "Train Loss: 0.4446 Acc: 0.8357\n",
      "Val Loss: 0.6296 Acc: 0.7840\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "Train Loss: 0.4239 Acc: 0.8433\n",
      "Val Loss: 0.5985 Acc: 0.7870\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "Train Loss: 0.4308 Acc: 0.8445\n",
      "Val Loss: 0.5419 Acc: 0.8220\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "Train Loss: 0.4458 Acc: 0.8340\n",
      "Val Loss: 0.5058 Acc: 0.8260\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "Train Loss: 0.4412 Acc: 0.8387\n",
      "Val Loss: 0.5404 Acc: 0.8170\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "Train Loss: 0.4353 Acc: 0.8450\n",
      "Val Loss: 0.5153 Acc: 0.8280\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "Train Loss: 0.4293 Acc: 0.8380\n",
      "Val Loss: 0.5517 Acc: 0.8110\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "Train Loss: 0.4639 Acc: 0.8325\n",
      "Val Loss: 0.5637 Acc: 0.8060\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "Train Loss: 0.4345 Acc: 0.8423\n",
      "Val Loss: 0.5514 Acc: 0.8000\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "Train Loss: 0.4273 Acc: 0.8445\n",
      "Val Loss: 0.5084 Acc: 0.8220\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "Train Loss: 0.4614 Acc: 0.8343\n",
      "Val Loss: 0.5607 Acc: 0.7990\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "Train Loss: 0.4289 Acc: 0.8485\n",
      "Val Loss: 0.5296 Acc: 0.8100\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "Train Loss: 0.4390 Acc: 0.8375\n",
      "Val Loss: 0.5337 Acc: 0.8130\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "Train Loss: 0.4306 Acc: 0.8347\n",
      "Val Loss: 0.5001 Acc: 0.8310\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "Train Loss: 0.4508 Acc: 0.8377\n",
      "Val Loss: 0.5453 Acc: 0.8100\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "Train Loss: 0.4411 Acc: 0.8345\n",
      "Val Loss: 0.5187 Acc: 0.8190\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "Train Loss: 0.4444 Acc: 0.8413\n",
      "Val Loss: 0.5185 Acc: 0.8250\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "Train Loss: 0.4537 Acc: 0.8375\n",
      "Val Loss: 0.5667 Acc: 0.8060\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "Train Loss: 0.4489 Acc: 0.8377\n",
      "Val Loss: 0.5340 Acc: 0.8140\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "Train Loss: 0.4136 Acc: 0.8513\n",
      "Val Loss: 0.5406 Acc: 0.8070\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "Train Loss: 0.4387 Acc: 0.8303\n",
      "Val Loss: 0.5090 Acc: 0.8270\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "Train Loss: 0.4155 Acc: 0.8380\n",
      "Val Loss: 0.5779 Acc: 0.7880\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "Train Loss: 0.4407 Acc: 0.8360\n",
      "Val Loss: 0.5234 Acc: 0.8100\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "Train Loss: 0.4237 Acc: 0.8410\n",
      "Val Loss: 0.5512 Acc: 0.7960\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "Train Loss: 0.4331 Acc: 0.8435\n",
      "Val Loss: 0.5465 Acc: 0.8030\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "Train Loss: 0.4207 Acc: 0.8435\n",
      "Val Loss: 0.5208 Acc: 0.8240\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "Train Loss: 0.4341 Acc: 0.8357\n",
      "Val Loss: 0.5568 Acc: 0.8010\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "Train Loss: 0.4289 Acc: 0.8380\n",
      "Val Loss: 0.5130 Acc: 0.8190\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "Train Loss: 0.4276 Acc: 0.8423\n",
      "Val Loss: 0.5006 Acc: 0.8230\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "Train Loss: 0.4280 Acc: 0.8427\n",
      "Val Loss: 0.5661 Acc: 0.8030\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "Train Loss: 0.4359 Acc: 0.8450\n",
      "Val Loss: 0.5161 Acc: 0.8270\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "Train Loss: 0.4226 Acc: 0.8453\n",
      "Val Loss: 0.5248 Acc: 0.8240\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "Train Loss: 0.4344 Acc: 0.8317\n",
      "Val Loss: 0.4966 Acc: 0.8350\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "Train Loss: 0.4169 Acc: 0.8485\n",
      "Val Loss: 0.5169 Acc: 0.8250\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "Train Loss: 0.4259 Acc: 0.8430\n",
      "Val Loss: 0.5596 Acc: 0.8060\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "Train Loss: 0.4153 Acc: 0.8488\n",
      "Val Loss: 0.5172 Acc: 0.8240\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "Train Loss: 0.4272 Acc: 0.8415\n",
      "Val Loss: 0.5520 Acc: 0.8070\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "Train Loss: 0.4204 Acc: 0.8448\n",
      "Val Loss: 0.5346 Acc: 0.8130\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "Train Loss: 0.4164 Acc: 0.8453\n",
      "Val Loss: 0.5127 Acc: 0.8270\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "Train Loss: 0.4250 Acc: 0.8403\n",
      "Val Loss: 0.5125 Acc: 0.8280\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "Train Loss: 0.4095 Acc: 0.8503\n",
      "Val Loss: 0.5440 Acc: 0.8030\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "Train Loss: 0.4127 Acc: 0.8435\n",
      "Val Loss: 0.5175 Acc: 0.8250\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "Train Loss: 0.4315 Acc: 0.8375\n",
      "Val Loss: 0.5230 Acc: 0.8250\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "Train Loss: 0.4376 Acc: 0.8455\n",
      "Val Loss: 0.5218 Acc: 0.8110\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "Train Loss: 0.4313 Acc: 0.8483\n",
      "Val Loss: 0.5328 Acc: 0.8250\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "Train Loss: 0.4447 Acc: 0.8320\n",
      "Val Loss: 0.5190 Acc: 0.8200\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "Train Loss: 0.4244 Acc: 0.8468\n",
      "Val Loss: 0.6184 Acc: 0.7890\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "Train Loss: 0.4341 Acc: 0.8397\n",
      "Val Loss: 0.5514 Acc: 0.8180\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "Train Loss: 0.4385 Acc: 0.8405\n",
      "Val Loss: 0.5525 Acc: 0.8030\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "Train Loss: 0.4337 Acc: 0.8458\n",
      "Val Loss: 0.5066 Acc: 0.8280\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "Train Loss: 0.4359 Acc: 0.8443\n",
      "Val Loss: 0.5208 Acc: 0.8140\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "Train Loss: 0.4389 Acc: 0.8405\n",
      "Val Loss: 0.5283 Acc: 0.8170\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "Train Loss: 0.4468 Acc: 0.8377\n",
      "Val Loss: 0.5136 Acc: 0.8230\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "Train Loss: 0.4256 Acc: 0.8395\n",
      "Val Loss: 0.5246 Acc: 0.8150\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "Train Loss: 0.4149 Acc: 0.8407\n",
      "Val Loss: 0.5332 Acc: 0.8060\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "Train Loss: 0.4280 Acc: 0.8373\n",
      "Val Loss: 0.5042 Acc: 0.8360\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "Train Loss: 0.4086 Acc: 0.8508\n",
      "Val Loss: 0.5053 Acc: 0.8310\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "Train Loss: 0.4423 Acc: 0.8390\n",
      "Val Loss: 0.5298 Acc: 0.8290\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "Train Loss: 0.4145 Acc: 0.8508\n",
      "Val Loss: 0.5244 Acc: 0.8240\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "Train Loss: 0.4284 Acc: 0.8438\n",
      "Val Loss: 0.5462 Acc: 0.8060\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "Train Loss: 0.4298 Acc: 0.8403\n",
      "Val Loss: 0.5138 Acc: 0.8240\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "Train Loss: 0.4237 Acc: 0.8415\n",
      "Val Loss: 0.5036 Acc: 0.8340\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "Train Loss: 0.4135 Acc: 0.8450\n",
      "Val Loss: 0.5358 Acc: 0.8080\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "Train Loss: 0.4369 Acc: 0.8430\n",
      "Val Loss: 0.4932 Acc: 0.8260\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "Train Loss: 0.4190 Acc: 0.8483\n",
      "Val Loss: 0.5621 Acc: 0.8050\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4441 Acc: 0.8330\n",
      "Val Loss: 0.5590 Acc: 0.8110\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "Train Loss: 0.4475 Acc: 0.8405\n",
      "Val Loss: 0.5840 Acc: 0.7920\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "Train Loss: 0.4310 Acc: 0.8433\n",
      "Val Loss: 0.5130 Acc: 0.8270\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "Train Loss: 0.4452 Acc: 0.8383\n",
      "Val Loss: 0.5345 Acc: 0.8150\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "Train Loss: 0.4273 Acc: 0.8500\n",
      "Val Loss: 0.5156 Acc: 0.8370\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "Train Loss: 0.4353 Acc: 0.8427\n",
      "Val Loss: 0.5251 Acc: 0.8240\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "Train Loss: 0.4602 Acc: 0.8375\n",
      "Val Loss: 0.5292 Acc: 0.8180\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "Train Loss: 0.4378 Acc: 0.8403\n",
      "Val Loss: 0.5199 Acc: 0.8260\n",
      "\n",
      "Training complete in 209m 59s\n",
      "Best val Acc: 0.841000\n",
      "Epoch 0/199\n",
      "----------\n",
      "Train Loss: 0.9748 Acc: 0.6442\n",
      "Val Loss: 0.8691 Acc: 0.6930\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "Train Loss: 0.6662 Acc: 0.7670\n",
      "Val Loss: 0.7613 Acc: 0.7300\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "Train Loss: 0.5842 Acc: 0.7923\n",
      "Val Loss: 0.7278 Acc: 0.7270\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "Train Loss: 0.5727 Acc: 0.7828\n",
      "Val Loss: 0.6190 Acc: 0.7910\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "Train Loss: 0.5474 Acc: 0.7973\n",
      "Val Loss: 0.6121 Acc: 0.7890\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "Train Loss: 0.5210 Acc: 0.8025\n",
      "Val Loss: 0.6115 Acc: 0.7890\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "Train Loss: 0.5048 Acc: 0.8175\n",
      "Val Loss: 0.5857 Acc: 0.7930\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "Train Loss: 0.5145 Acc: 0.8107\n",
      "Val Loss: 0.6086 Acc: 0.7860\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "Train Loss: 0.5108 Acc: 0.8023\n",
      "Val Loss: 0.5639 Acc: 0.7960\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "Train Loss: 0.4969 Acc: 0.8145\n",
      "Val Loss: 0.5864 Acc: 0.7950\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "Train Loss: 0.4906 Acc: 0.8197\n",
      "Val Loss: 0.5655 Acc: 0.8060\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "Train Loss: 0.5067 Acc: 0.8140\n",
      "Val Loss: 0.5912 Acc: 0.7880\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "Train Loss: 0.4800 Acc: 0.8257\n",
      "Val Loss: 0.5787 Acc: 0.7880\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "Train Loss: 0.4883 Acc: 0.8167\n",
      "Val Loss: 0.5699 Acc: 0.7960\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "Train Loss: 0.4927 Acc: 0.8185\n",
      "Val Loss: 0.5569 Acc: 0.8060\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "Train Loss: 0.4814 Acc: 0.8280\n",
      "Val Loss: 0.5790 Acc: 0.7900\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "Train Loss: 0.4748 Acc: 0.8257\n",
      "Val Loss: 0.5795 Acc: 0.7870\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "Train Loss: 0.4720 Acc: 0.8347\n",
      "Val Loss: 0.5431 Acc: 0.8010\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "Train Loss: 0.4788 Acc: 0.8233\n",
      "Val Loss: 0.6947 Acc: 0.7290\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "Train Loss: 0.4817 Acc: 0.8227\n",
      "Val Loss: 0.5675 Acc: 0.7960\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "Train Loss: 0.4605 Acc: 0.8285\n",
      "Val Loss: 0.5477 Acc: 0.8050\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "Train Loss: 0.4777 Acc: 0.8235\n",
      "Val Loss: 0.5553 Acc: 0.8020\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "Train Loss: 0.4659 Acc: 0.8273\n",
      "Val Loss: 0.5870 Acc: 0.7940\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "Train Loss: 0.4905 Acc: 0.8203\n",
      "Val Loss: 0.5542 Acc: 0.8040\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "Train Loss: 0.4597 Acc: 0.8280\n",
      "Val Loss: 0.5767 Acc: 0.7920\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "Train Loss: 0.4754 Acc: 0.8265\n",
      "Val Loss: 0.6009 Acc: 0.7820\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "Train Loss: 0.4687 Acc: 0.8245\n",
      "Val Loss: 0.5742 Acc: 0.7980\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "Train Loss: 0.4535 Acc: 0.8295\n",
      "Val Loss: 0.5419 Acc: 0.8170\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "Train Loss: 0.4410 Acc: 0.8365\n",
      "Val Loss: 0.5186 Acc: 0.8230\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "Train Loss: 0.4587 Acc: 0.8343\n",
      "Val Loss: 0.6399 Acc: 0.7490\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "Train Loss: 0.4625 Acc: 0.8247\n",
      "Val Loss: 0.5526 Acc: 0.8090\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "Train Loss: 0.4435 Acc: 0.8353\n",
      "Val Loss: 0.5156 Acc: 0.8250\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "Train Loss: 0.4525 Acc: 0.8340\n",
      "Val Loss: 0.5567 Acc: 0.8030\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "Train Loss: 0.4683 Acc: 0.8305\n",
      "Val Loss: 0.5809 Acc: 0.7990\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "Train Loss: 0.4380 Acc: 0.8310\n",
      "Val Loss: 0.5488 Acc: 0.8020\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "Train Loss: 0.4540 Acc: 0.8300\n",
      "Val Loss: 0.5249 Acc: 0.8190\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "Train Loss: 0.4397 Acc: 0.8357\n",
      "Val Loss: 0.5809 Acc: 0.8010\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "Train Loss: 0.4445 Acc: 0.8297\n",
      "Val Loss: 0.5318 Acc: 0.8170\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "Train Loss: 0.4605 Acc: 0.8265\n",
      "Val Loss: 0.5213 Acc: 0.8240\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "Train Loss: 0.4438 Acc: 0.8377\n",
      "Val Loss: 0.5192 Acc: 0.8260\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "Train Loss: 0.4358 Acc: 0.8357\n",
      "Val Loss: 0.5369 Acc: 0.8170\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "Train Loss: 0.4439 Acc: 0.8323\n",
      "Val Loss: 0.5248 Acc: 0.8140\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "Train Loss: 0.4700 Acc: 0.8293\n",
      "Val Loss: 0.5180 Acc: 0.8200\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "Train Loss: 0.4337 Acc: 0.8395\n",
      "Val Loss: 0.5382 Acc: 0.8160\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "Train Loss: 0.4529 Acc: 0.8285\n",
      "Val Loss: 0.5226 Acc: 0.8180\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "Train Loss: 0.4599 Acc: 0.8295\n",
      "Val Loss: 0.5339 Acc: 0.8100\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "Train Loss: 0.4394 Acc: 0.8365\n",
      "Val Loss: 0.5114 Acc: 0.8220\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "Train Loss: 0.4459 Acc: 0.8367\n",
      "Val Loss: 0.5173 Acc: 0.8220\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "Train Loss: 0.4426 Acc: 0.8327\n",
      "Val Loss: 0.6181 Acc: 0.7840\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "Train Loss: 0.4379 Acc: 0.8403\n",
      "Val Loss: 0.5070 Acc: 0.8260\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "Train Loss: 0.4269 Acc: 0.8400\n",
      "Val Loss: 0.5302 Acc: 0.8170\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "Train Loss: 0.4532 Acc: 0.8360\n",
      "Val Loss: 0.5172 Acc: 0.8200\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "Train Loss: 0.4373 Acc: 0.8355\n",
      "Val Loss: 0.5248 Acc: 0.8140\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "Train Loss: 0.4417 Acc: 0.8413\n",
      "Val Loss: 0.5219 Acc: 0.8210\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "Train Loss: 0.4543 Acc: 0.8323\n",
      "Val Loss: 0.5296 Acc: 0.8090\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "Train Loss: 0.4327 Acc: 0.8423\n",
      "Val Loss: 0.5494 Acc: 0.8130\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "Train Loss: 0.4557 Acc: 0.8295\n",
      "Val Loss: 0.5346 Acc: 0.8050\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "Train Loss: 0.4424 Acc: 0.8340\n",
      "Val Loss: 0.5236 Acc: 0.8140\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "Train Loss: 0.4276 Acc: 0.8465\n",
      "Val Loss: 0.5650 Acc: 0.7970\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "Train Loss: 0.4557 Acc: 0.8350\n",
      "Val Loss: 0.5123 Acc: 0.8240\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "Train Loss: 0.4382 Acc: 0.8390\n",
      "Val Loss: 0.5295 Acc: 0.8170\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "Train Loss: 0.4424 Acc: 0.8390\n",
      "Val Loss: 0.5770 Acc: 0.7990\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "Train Loss: 0.4660 Acc: 0.8283\n",
      "Val Loss: 0.5271 Acc: 0.8200\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "Train Loss: 0.4399 Acc: 0.8393\n",
      "Val Loss: 0.5909 Acc: 0.7830\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "Train Loss: 0.4574 Acc: 0.8340\n",
      "Val Loss: 0.5190 Acc: 0.8240\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "Train Loss: 0.4298 Acc: 0.8425\n",
      "Val Loss: 0.5281 Acc: 0.8080\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "Train Loss: 0.4429 Acc: 0.8325\n",
      "Val Loss: 0.5060 Acc: 0.8320\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "Train Loss: 0.4412 Acc: 0.8377\n",
      "Val Loss: 0.5565 Acc: 0.7960\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "Train Loss: 0.4325 Acc: 0.8363\n",
      "Val Loss: 0.5531 Acc: 0.8080\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "Train Loss: 0.4259 Acc: 0.8453\n",
      "Val Loss: 0.5637 Acc: 0.7920\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "Train Loss: 0.4516 Acc: 0.8353\n",
      "Val Loss: 0.5667 Acc: 0.8000\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "Train Loss: 0.4624 Acc: 0.8310\n",
      "Val Loss: 0.5830 Acc: 0.7930\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "Train Loss: 0.4386 Acc: 0.8387\n",
      "Val Loss: 0.5765 Acc: 0.7820\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "Train Loss: 0.4702 Acc: 0.8307\n",
      "Val Loss: 0.5886 Acc: 0.7880\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "Train Loss: 0.4337 Acc: 0.8413\n",
      "Val Loss: 0.5456 Acc: 0.8100\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "Train Loss: 0.4391 Acc: 0.8387\n",
      "Val Loss: 0.5057 Acc: 0.8280\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "Train Loss: 0.4121 Acc: 0.8465\n",
      "Val Loss: 0.5190 Acc: 0.8170\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "Train Loss: 0.4465 Acc: 0.8345\n",
      "Val Loss: 0.5164 Acc: 0.8290\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "Train Loss: 0.4497 Acc: 0.8405\n",
      "Val Loss: 0.5429 Acc: 0.8110\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "Train Loss: 0.4399 Acc: 0.8347\n",
      "Val Loss: 0.5744 Acc: 0.7990\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "Train Loss: 0.4241 Acc: 0.8438\n",
      "Val Loss: 0.5953 Acc: 0.7860\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "Train Loss: 0.4268 Acc: 0.8387\n",
      "Val Loss: 0.5877 Acc: 0.7820\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "Train Loss: 0.4480 Acc: 0.8320\n",
      "Val Loss: 0.5302 Acc: 0.8160\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "Train Loss: 0.4535 Acc: 0.8365\n",
      "Val Loss: 0.5030 Acc: 0.8310\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "Train Loss: 0.4305 Acc: 0.8433\n",
      "Val Loss: 0.4986 Acc: 0.8380\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "Train Loss: 0.4278 Acc: 0.8397\n",
      "Val Loss: 0.5203 Acc: 0.8160\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "Train Loss: 0.4401 Acc: 0.8353\n",
      "Val Loss: 0.5035 Acc: 0.8220\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "Train Loss: 0.4542 Acc: 0.8307\n",
      "Val Loss: 0.5167 Acc: 0.8180\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4422 Acc: 0.8410\n",
      "Val Loss: 0.5334 Acc: 0.8170\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "Train Loss: 0.4434 Acc: 0.8377\n",
      "Val Loss: 0.5766 Acc: 0.7890\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "Train Loss: 0.4583 Acc: 0.8277\n",
      "Val Loss: 0.5293 Acc: 0.8100\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "Train Loss: 0.4424 Acc: 0.8367\n",
      "Val Loss: 0.5430 Acc: 0.8110\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "Train Loss: 0.4286 Acc: 0.8475\n",
      "Val Loss: 0.5417 Acc: 0.8030\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "Train Loss: 0.4641 Acc: 0.8253\n",
      "Val Loss: 0.5318 Acc: 0.8120\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "Train Loss: 0.4243 Acc: 0.8420\n",
      "Val Loss: 0.5081 Acc: 0.8190\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "Train Loss: 0.4444 Acc: 0.8373\n",
      "Val Loss: 0.5256 Acc: 0.8210\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "Train Loss: 0.4403 Acc: 0.8373\n",
      "Val Loss: 0.5612 Acc: 0.8070\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "Train Loss: 0.4256 Acc: 0.8433\n",
      "Val Loss: 0.5106 Acc: 0.8270\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "Train Loss: 0.4456 Acc: 0.8380\n",
      "Val Loss: 0.5385 Acc: 0.8040\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "Train Loss: 0.4465 Acc: 0.8395\n",
      "Val Loss: 0.5091 Acc: 0.8270\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "Train Loss: 0.4282 Acc: 0.8405\n",
      "Val Loss: 0.5233 Acc: 0.8120\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "Train Loss: 0.4405 Acc: 0.8367\n",
      "Val Loss: 0.5062 Acc: 0.8320\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "Train Loss: 0.4357 Acc: 0.8380\n",
      "Val Loss: 0.4863 Acc: 0.8320\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "Train Loss: 0.4315 Acc: 0.8417\n",
      "Val Loss: 0.4939 Acc: 0.8360\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "Train Loss: 0.4482 Acc: 0.8303\n",
      "Val Loss: 0.5140 Acc: 0.8240\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "Train Loss: 0.4224 Acc: 0.8443\n",
      "Val Loss: 0.5164 Acc: 0.8140\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "Train Loss: 0.4346 Acc: 0.8425\n",
      "Val Loss: 0.5229 Acc: 0.8140\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "Train Loss: 0.4596 Acc: 0.8335\n",
      "Val Loss: 0.5818 Acc: 0.8030\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "Train Loss: 0.4503 Acc: 0.8417\n",
      "Val Loss: 0.5375 Acc: 0.8180\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "Train Loss: 0.4310 Acc: 0.8365\n",
      "Val Loss: 0.6067 Acc: 0.7840\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "Train Loss: 0.4479 Acc: 0.8390\n",
      "Val Loss: 0.5370 Acc: 0.8110\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "Train Loss: 0.4221 Acc: 0.8473\n",
      "Val Loss: 0.5456 Acc: 0.8110\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "Train Loss: 0.4226 Acc: 0.8473\n",
      "Val Loss: 0.5534 Acc: 0.8050\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "Train Loss: 0.4118 Acc: 0.8520\n",
      "Val Loss: 0.5238 Acc: 0.8240\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "Train Loss: 0.4394 Acc: 0.8340\n",
      "Val Loss: 0.5453 Acc: 0.8030\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "Train Loss: 0.4476 Acc: 0.8395\n",
      "Val Loss: 0.5399 Acc: 0.8050\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "Train Loss: 0.4276 Acc: 0.8425\n",
      "Val Loss: 0.5037 Acc: 0.8220\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "Train Loss: 0.4441 Acc: 0.8395\n",
      "Val Loss: 0.5174 Acc: 0.8260\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "Train Loss: 0.4349 Acc: 0.8367\n",
      "Val Loss: 0.5135 Acc: 0.8310\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "Train Loss: 0.4298 Acc: 0.8450\n",
      "Val Loss: 0.5764 Acc: 0.7990\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "Train Loss: 0.4425 Acc: 0.8410\n",
      "Val Loss: 0.5158 Acc: 0.8200\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "Train Loss: 0.4387 Acc: 0.8397\n",
      "Val Loss: 0.4998 Acc: 0.8300\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "Train Loss: 0.4190 Acc: 0.8413\n",
      "Val Loss: 0.5305 Acc: 0.8050\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "Train Loss: 0.4328 Acc: 0.8383\n",
      "Val Loss: 0.5905 Acc: 0.7940\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "Train Loss: 0.4468 Acc: 0.8417\n",
      "Val Loss: 0.5591 Acc: 0.8020\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "Train Loss: 0.4467 Acc: 0.8280\n",
      "Val Loss: 0.4931 Acc: 0.8340\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "Train Loss: 0.4366 Acc: 0.8403\n",
      "Val Loss: 0.5236 Acc: 0.8220\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "Train Loss: 0.4156 Acc: 0.8478\n",
      "Val Loss: 0.5274 Acc: 0.8270\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "Train Loss: 0.4290 Acc: 0.8427\n",
      "Val Loss: 0.5195 Acc: 0.8240\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "Train Loss: 0.4331 Acc: 0.8407\n",
      "Val Loss: 0.4944 Acc: 0.8320\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "Train Loss: 0.4350 Acc: 0.8383\n",
      "Val Loss: 0.5049 Acc: 0.8310\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "Train Loss: 0.4167 Acc: 0.8435\n",
      "Val Loss: 0.5037 Acc: 0.8290\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "Train Loss: 0.4027 Acc: 0.8470\n",
      "Val Loss: 0.5336 Acc: 0.8240\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "Train Loss: 0.4247 Acc: 0.8427\n",
      "Val Loss: 0.5486 Acc: 0.8110\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "Train Loss: 0.4410 Acc: 0.8387\n",
      "Val Loss: 0.5296 Acc: 0.8180\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "Train Loss: 0.4435 Acc: 0.8370\n",
      "Val Loss: 0.5369 Acc: 0.8120\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "Train Loss: 0.4421 Acc: 0.8337\n",
      "Val Loss: 0.5628 Acc: 0.8010\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "Train Loss: 0.4558 Acc: 0.8370\n",
      "Val Loss: 0.5776 Acc: 0.8120\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "Train Loss: 0.4274 Acc: 0.8423\n",
      "Val Loss: 0.5252 Acc: 0.8210\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "Train Loss: 0.4298 Acc: 0.8463\n",
      "Val Loss: 0.5039 Acc: 0.8290\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "Train Loss: 0.4092 Acc: 0.8480\n",
      "Val Loss: 0.5065 Acc: 0.8340\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "Train Loss: 0.4315 Acc: 0.8387\n",
      "Val Loss: 0.5355 Acc: 0.8150\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "Train Loss: 0.4354 Acc: 0.8360\n",
      "Val Loss: 0.5008 Acc: 0.8310\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "Train Loss: 0.4477 Acc: 0.8353\n",
      "Val Loss: 0.5121 Acc: 0.8260\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "Train Loss: 0.4388 Acc: 0.8403\n",
      "Val Loss: 0.5483 Acc: 0.8060\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "Train Loss: 0.4367 Acc: 0.8430\n",
      "Val Loss: 0.5567 Acc: 0.8110\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "Train Loss: 0.4089 Acc: 0.8478\n",
      "Val Loss: 0.5171 Acc: 0.8150\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "Train Loss: 0.4258 Acc: 0.8417\n",
      "Val Loss: 0.5616 Acc: 0.7930\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "Train Loss: 0.4318 Acc: 0.8397\n",
      "Val Loss: 0.4924 Acc: 0.8290\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "Train Loss: 0.4159 Acc: 0.8468\n",
      "Val Loss: 0.5369 Acc: 0.8090\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "Train Loss: 0.4269 Acc: 0.8465\n",
      "Val Loss: 0.5577 Acc: 0.8070\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "Train Loss: 0.4326 Acc: 0.8400\n",
      "Val Loss: 0.5227 Acc: 0.8270\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "Train Loss: 0.4167 Acc: 0.8443\n",
      "Val Loss: 0.5118 Acc: 0.8260\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "Train Loss: 0.4333 Acc: 0.8370\n",
      "Val Loss: 0.5324 Acc: 0.8130\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "Train Loss: 0.4160 Acc: 0.8458\n",
      "Val Loss: 0.6134 Acc: 0.7800\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "Train Loss: 0.4476 Acc: 0.8365\n",
      "Val Loss: 0.5023 Acc: 0.8340\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "Train Loss: 0.4075 Acc: 0.8483\n",
      "Val Loss: 0.4995 Acc: 0.8270\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "Train Loss: 0.4334 Acc: 0.8367\n",
      "Val Loss: 0.5154 Acc: 0.8270\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "Train Loss: 0.4352 Acc: 0.8403\n",
      "Val Loss: 0.5050 Acc: 0.8300\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "Train Loss: 0.4185 Acc: 0.8523\n",
      "Val Loss: 0.5020 Acc: 0.8200\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "Train Loss: 0.4399 Acc: 0.8413\n",
      "Val Loss: 0.5058 Acc: 0.8330\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "Train Loss: 0.4359 Acc: 0.8400\n",
      "Val Loss: 0.6061 Acc: 0.7890\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "Train Loss: 0.4396 Acc: 0.8407\n",
      "Val Loss: 0.6229 Acc: 0.7790\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "Train Loss: 0.4417 Acc: 0.8380\n",
      "Val Loss: 0.5106 Acc: 0.8240\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "Train Loss: 0.3978 Acc: 0.8543\n",
      "Val Loss: 0.4880 Acc: 0.8420\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "Train Loss: 0.4382 Acc: 0.8397\n",
      "Val Loss: 0.4936 Acc: 0.8380\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "Train Loss: 0.4156 Acc: 0.8460\n",
      "Val Loss: 0.5091 Acc: 0.8270\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "Train Loss: 0.4348 Acc: 0.8415\n",
      "Val Loss: 0.5755 Acc: 0.7930\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "Train Loss: 0.4238 Acc: 0.8463\n",
      "Val Loss: 0.5646 Acc: 0.8060\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "Train Loss: 0.4326 Acc: 0.8417\n",
      "Val Loss: 0.5410 Acc: 0.8080\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "Train Loss: 0.4165 Acc: 0.8528\n",
      "Val Loss: 0.5331 Acc: 0.8150\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "Train Loss: 0.4345 Acc: 0.8463\n",
      "Val Loss: 0.5086 Acc: 0.8360\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "Train Loss: 0.4816 Acc: 0.8275\n",
      "Val Loss: 0.4891 Acc: 0.8360\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "Train Loss: 0.4444 Acc: 0.8413\n",
      "Val Loss: 0.5209 Acc: 0.8220\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "Train Loss: 0.4492 Acc: 0.8350\n",
      "Val Loss: 0.5430 Acc: 0.8120\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "Train Loss: 0.4270 Acc: 0.8435\n",
      "Val Loss: 0.5295 Acc: 0.8180\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "Train Loss: 0.4227 Acc: 0.8440\n",
      "Val Loss: 0.5169 Acc: 0.8080\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "Train Loss: 0.4264 Acc: 0.8488\n",
      "Val Loss: 0.5516 Acc: 0.8020\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "Train Loss: 0.4123 Acc: 0.8533\n",
      "Val Loss: 0.4982 Acc: 0.8340\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "Train Loss: 0.4377 Acc: 0.8430\n",
      "Val Loss: 0.5444 Acc: 0.8000\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "Train Loss: 0.4315 Acc: 0.8425\n",
      "Val Loss: 0.5687 Acc: 0.7970\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "Train Loss: 0.4505 Acc: 0.8375\n",
      "Val Loss: 0.5224 Acc: 0.8150\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "Train Loss: 0.4141 Acc: 0.8470\n",
      "Val Loss: 0.5212 Acc: 0.8200\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "Train Loss: 0.4468 Acc: 0.8390\n",
      "Val Loss: 0.5183 Acc: 0.8080\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4289 Acc: 0.8395\n",
      "Val Loss: 0.5276 Acc: 0.8290\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "Train Loss: 0.4406 Acc: 0.8415\n",
      "Val Loss: 0.5038 Acc: 0.8250\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "Train Loss: 0.4545 Acc: 0.8355\n",
      "Val Loss: 0.5838 Acc: 0.7900\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "Train Loss: 0.4334 Acc: 0.8360\n",
      "Val Loss: 0.5602 Acc: 0.8100\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "Train Loss: 0.4216 Acc: 0.8490\n",
      "Val Loss: 0.5054 Acc: 0.8270\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "Train Loss: 0.4239 Acc: 0.8433\n",
      "Val Loss: 0.5466 Acc: 0.8150\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "Train Loss: 0.4357 Acc: 0.8353\n",
      "Val Loss: 0.6793 Acc: 0.7380\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "Train Loss: 0.4455 Acc: 0.8380\n",
      "Val Loss: 0.5034 Acc: 0.8250\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n",
      "Train Loss: 0.4101 Acc: 0.8498\n",
      "Val Loss: 0.5538 Acc: 0.8110\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "Train Loss: 0.4082 Acc: 0.8528\n",
      "Val Loss: 0.5169 Acc: 0.8170\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "Train Loss: 0.4162 Acc: 0.8468\n",
      "Val Loss: 0.5810 Acc: 0.7920\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "Train Loss: 0.4249 Acc: 0.8453\n",
      "Val Loss: 0.5058 Acc: 0.8360\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "Train Loss: 0.4280 Acc: 0.8425\n",
      "Val Loss: 0.4961 Acc: 0.8310\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "Train Loss: 0.4292 Acc: 0.8468\n",
      "Val Loss: 0.5063 Acc: 0.8340\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "Train Loss: 0.4390 Acc: 0.8403\n",
      "Val Loss: 0.5326 Acc: 0.8140\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "Train Loss: 0.4252 Acc: 0.8463\n",
      "Val Loss: 0.5360 Acc: 0.8130\n",
      "\n",
      "Training complete in 219m 43s\n",
      "Best val Acc: 0.842000\n"
     ]
    }
   ],
   "source": [
    "# Get Cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train Model\n",
    "list_loss_train = []\n",
    "list_acc_train = []\n",
    "list_loss_val = []\n",
    "list_acc_val = []\n",
    "list_preds_vec = []\n",
    "list_true_vec = []\n",
    "\n",
    "for i in range(2):\n",
    "    model_ft = initialize_model(len(classes))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_ft.parameters())\n",
    "\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    model_ft, loss_train, acc_train, loss_val, acc_val = train_model(model_ft, criterion, optimizer,\n",
    "                       num_epochs=200)\n",
    "    \n",
    "    preds_vec, true_vec = prediciton(model_ft)\n",
    "    \n",
    "    list_loss_train.append(loss_train)\n",
    "    list_acc_train.append(acc_train)\n",
    "    list_loss_val.append(loss_val)\n",
    "    list_acc_val.append(acc_val)\n",
    "    list_preds_vec.append(preds_vec)\n",
    "    list_true_vec.append(true_vec)\n",
    "    \n",
    "    torch.save(model_ft, f'Resnet_224_{i}_{date}')\n",
    "# Save Pickles\n",
    "results = open(f'Resnet_results_224_{date}', 'wb')\n",
    "pickle.dump([[list_loss_train],[list_acc_train],[list_loss_val],[list_acc_val],[list_preds_vec],[list_true_vec]],results)\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
